{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "04285f90",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle as pkl\n",
    "import xarray as xr"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c24d6135",
   "metadata": {},
   "source": [
    "Necessary funtions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "21141cda",
   "metadata": {},
   "outputs": [],
   "source": [
    "def r_trans(y):\n",
    "    y = np.asarray(y)\n",
    "    return np.exp(((y - a) * (obs_log_max -  obs_log_min) / (b - a)) + obs_log_min)\n",
    "\n",
    "def reverse_transform_std(y):\n",
    "    return ((y)*(obs_log_max - obs_log_min) / (b - a))\n",
    "\n",
    "def recube(in_array):\n",
    "\n",
    "    plev_len = 52\n",
    "    lat_len = 36\n",
    "    time_len = 31 * 12\n",
    "\n",
    "    output = np.zeros([time_len, plev_len, lat_len])\n",
    "\n",
    "    for t in range(time_len):\n",
    "        output[t,:,:] = in_array[plev_len * lat_len * (t): plev_len * lat_len * (t+1)].reshape([plev_len, lat_len])\n",
    "    \n",
    "    return output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "342222fa",
   "metadata": {},
   "source": [
    "Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "60dd2405",
   "metadata": {},
   "outputs": [],
   "source": [
    "in_dir = './outputRAW/'\n",
    "lat = pkl.load(open(in_dir + 'lats.pkl', 'rb'))\n",
    "plev = np.unique(pkl.load(open(in_dir + 'plevs.pkl', 'rb'))/100)[::-1]\n",
    "date = pkl.load(open(in_dir + 'dates.pkl', 'rb'))\n",
    "\n",
    "num_models = 13\n",
    "df = pd.read_pickle('./vmro3_refC1SD_70x36_13mdls_masked_extrap_and_interp.pkl')\n",
    "plev_orig = np.unique(df['plev'])[::-1]\n",
    "df = df[df['plev'] < 50000]\n",
    "df = df[df['plev'] > 30]\n",
    "obs = df['obs_toz'].copy()\n",
    "obs[np.log10(obs) < -9] = np.nan\n",
    "df['obs_toz'] = obs\n",
    "\n",
    "obs = recube(df['obs_toz'].values)\n",
    "train_mask = recube(df['train'].values).astype(np.bool)\n",
    "test_mask = recube(df['test'].values).astype(np.bool)\n",
    "interp_mask = recube(df['temp_interp'].values).astype(np.bool)\n",
    "extrap_mask = recube(df['temp_extrap'].values).astype(np.bool)\n",
    "\n",
    "obs_train = obs.copy()\n",
    "obs_train[~train_mask] = np.nan\n",
    "obs_test = obs.copy()\n",
    "obs_test[~test_mask] = np.nan\n",
    "obs_interp = obs.copy()\n",
    "obs_interp[~interp_mask] = np.nan\n",
    "obs_extrap = obs.copy()\n",
    "obs_extrap[~extrap_mask] = np.nan\n",
    "\n",
    "obs_min = df['obs_toz'].min()\n",
    "obs_max = df['obs_toz'].max()\n",
    "\n",
    "obs_log_max = np.log(obs_max)\n",
    "obs_log_min = np.log(obs_min)\n",
    "a, b = [-1, 1]\n",
    "\n",
    "# BNN output\n",
    "weights = pkl.load(open(in_dir + 'weights.pkl', 'rb'))\n",
    "bias_raw = pkl.load(open(in_dir + 'bias.pkl', 'rb')) \n",
    "noise_raw = pkl.load(open(in_dir + 'noise.pkl', 'rb')) \n",
    "std_raw = recube(pkl.load(open(in_dir + 'std.pkl', 'rb')))\n",
    "pred_raw = recube(pkl.load(open(in_dir + 'pred.pkl', 'rb')))\n",
    "epi_raw = pkl.load(open(in_dir + 'epi.pkl', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "17afa688",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find the bounds of prediction Â±1,2,3 std then convert to real values\n",
    "p1plus = r_trans(pred_raw + std_raw)\n",
    "p2plus = r_trans(pred_raw + 2 * std_raw)\n",
    "p3plus = r_trans(pred_raw + 3 * std_raw)\n",
    "p1minus = r_trans(pred_raw - std_raw)\n",
    "p2minus = r_trans(pred_raw - 2 * std_raw)\n",
    "p3minus = r_trans(pred_raw - 3 * std_raw)\n",
    "pred = r_trans(pred_raw)\n",
    "\n",
    "# This is also done for noise\n",
    "p1plusn = r_trans(pred_raw + noise_raw)\n",
    "p2plusn = r_trans(pred_raw + 2 * noise_raw)\n",
    "p3plusn = r_trans(pred_raw + 3 * noise_raw)\n",
    "p1minusn = r_trans(pred_raw - noise_raw)\n",
    "p2minusn = r_trans(pred_raw - 2 * noise_raw)\n",
    "p3minusn = r_trans(pred_raw - 3 * noise_raw)\n",
    "\n",
    "# and epistemic uncertainty\n",
    "p1pluse = r_trans(pred_raw + epi_raw)\n",
    "p2pluse = r_trans(pred_raw + 2 * epi_raw)\n",
    "p3pluse = r_trans(pred_raw + 3 * epi_raw)\n",
    "p1minuse = r_trans(pred_raw - epi_raw)\n",
    "p2minuse = r_trans(pred_raw - 2 * epi_raw)\n",
    "p3minuse = r_trans(pred_raw - 3 * epi_raw)\n",
    "\n",
    "# These values are estimates of std, noise and epi. \n",
    "# They are only estimates as the distribution is asymmetric\n",
    "std1sigma = (p1plus - p1minus) / 2\n",
    "std2sigma = (p2plus - p2minus) / 2\n",
    "std3sigma = (p3plus - p3minus) / 2\n",
    "\n",
    "noise1sigma = (p1plusn - p1minusn) / 2\n",
    "noise2sigma = (p2plusn - p2minusn) / 2\n",
    "noise3sigma = (p3plusn - p3minusn) / 2\n",
    "\n",
    "# Epistemic uncertainty could also be found by descaling all the\n",
    "# individual predictions and finding the std across them\n",
    "epi1sigma = (p1pluse - p1minuse) / 2\n",
    "epi2sigma = (p2pluse - p2minuse) / 2\n",
    "epi3sigma = (p3pluse - p3minuse) / 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f69b2c03",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = xr.Dataset(\n",
    "    data_vars=dict(\n",
    "        zmo3=([\"time\", \"air_pressure\", \"latitude\"], pred, {\"units\": \"mol/mol\", \"var_name\":\"Zonal mean ozone\"}),\n",
    "        zmo3_std=([\"time\", \"air_pressure\", \"latitude\"], std1sigma, {\"units\": \"mol/mol\", \"var_name\":\"Zonal mean ozone uncertainty\"}),\n",
    "    ),\n",
    "    coords=dict(\n",
    "        air_pressure=([\"air_pressure\"], plev, {\"units\": \"hPa\"}),\n",
    "        latitude=([\"latitude\"], lat),\n",
    "        time=date,\n",
    "    ),\n",
    "    attrs=dict(\n",
    "        Decription=\"Infilled estimate of zonal mean ozone concentration for a Bayesian neural network fusion of observations and chemistry-climate models\",\n",
    "        version='v0.1',\n",
    "        Author='Matt Amos: m.amos1@lancaster.ac.uk'\n",
    "    ),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "7c50d67c",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds.to_netcdf('zmo3_BNNOz.nc')"
   ]
  }
 ],
 "metadata": {
  "environment": {
   "name": "tf-gpu.1-15.m76",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/tf-gpu.1-15:m76"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
